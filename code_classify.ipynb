{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import random \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.cuda.amp as amp \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from pytorch_grad_cam import AblationCAM\n",
    "from pytorch_grad_cam.ablation_layer import AblationLayerVit\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from swin_transformer import SwinTransformer\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Augmentation\n",
    "- **rgb_to_lab_and_clahe function** - Performs conversion of RGB image to LAB color space after blurring (Gaussian) the Green (G) AND Blue (B) channels to emphasize the R channel and performs CLAHE. \n",
    "- **Augmentation** - Transforms like random Horizontal flip, Vertical flip, Rotation, Gaussian Blur, Affine, Perspective projection & MixUp are applied to create diversity in the training dataset to enhance model training and improve generalization.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_lab_and_clahe(img, clip_limit, tile_grid_size, blur_sigma):\n",
    "    \"\"\"\n",
    "    Convert an RGB image to LAB color space, apply CLAHE (Contrast Limited Adaptive Histogram Equalization).\n",
    "\n",
    "    Args:\n",
    "        img (PIL.Image): Input RGB image.\n",
    "        clip_limit (float): Clip limit for CLAHE.\n",
    "        tile_grid_size (tuple): Size of the tile grid for CLAHE.\n",
    "        blur_sigma (float): Standard deviation for Gaussian blur.\n",
    "\n",
    "    Returns:\n",
    "        lab_image (numpy.ndarray): LAB color space image.\n",
    "    \"\"\"        \n",
    "    rgb_r, rgb_g, rgb_b = cv2.split(np.array(img))\n",
    "    blurred_G = cv2.GaussianBlur(rgb_g, (5, 5), blur_sigma)\n",
    "    blurred_B = cv2.GaussianBlur(rgb_b, (5, 5), blur_sigma)\n",
    "\n",
    "    img = cv2.merge([rgb_r, blurred_G, blurred_B]) \n",
    "    lab_image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2Lab)\n",
    "    L, a, b = cv2.split(lab_image)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    clahed_L = clahe.apply(L)  \n",
    "    modified_lab_image = cv2.merge([clahed_L, a, b])\n",
    "    rgb_image = cv2.cvtColor(modified_lab_image, cv2.COLOR_LAB2RGB)\n",
    "    return lab_image \n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=180), \n",
    "    transforms.GaussianBlur(kernel_size=5, sigma=(1.0, 3.0)),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.25, 0.25), scale=(0.9, 1.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "    lambda x: rgb_to_lab_and_clahe(x, clip_limit=5.0, tile_grid_size=(8, 8), blur_sigma=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),   \n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    lambda x: rgb_to_lab_and_clahe(x, clip_limit=5.0, tile_grid_size=(8, 8), blur_sigma=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),  \n",
    "])\n",
    "\n",
    "def mixup(data, targets, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Applies MixUp augmentation to the input data and targets.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): Input data tensor.\n",
    "        targets (torch.Tensor): Target labels tensor.\n",
    "        alpha (float): MixUp hyperparameter controlling the mix ratio.\n",
    "\n",
    "    Returns:\n",
    "        mixed_data (torch.Tensor): Mixed data tensor.\n",
    "        targets_a (torch.Tensor): Targets for the first data sample.\n",
    "        targets_b (torch.Tensor): Targets for the second data sample.\n",
    "        lam (float): Lambda value representing the mix ratio.\n",
    "    \"\"\"\n",
    "    if alpha == 0:\n",
    "        return data, targets, targets, 1.0 \n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = data.size(0)\n",
    "    index = torch.randperm(batch_size)\n",
    "    mixed_data = lam * data + (1 - lam) * data[index, :]\n",
    "    targets_a, targets_b = targets, targets[index]\n",
    "    return mixed_data, targets_a, targets_b, lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device for PyTorch to CUDA if available, otherwise use CPU.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set a random seed for reproducibility and configure CUDA for benchmarking.\n",
    "seed = 2\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Define the file paths for the training and validation datasets.\n",
    "train_data_path = '/home/ee22s501/c2/data_classify/train'\n",
    "val_data_path = '/home/ee22s501/c2/data_classify/val'\n",
    "\n",
    "# Create PyTorch datasets with specified transformations.\n",
    "train_dataset = ImageFolder(train_data_path, transform=train_transform)\n",
    "val_dataset = ImageFolder(val_data_path, transform=val_transform)\n",
    "\n",
    "# Set the batch size and create data loaders for training and validation.\n",
    "batch_size = 8\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Criterion & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ee22s501/.local/lib/python3.10/site-packages/torch/functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Define the Swin Transformer model configuration.\n",
    "swin_config = {\n",
    "    'img_size': 224,\n",
    "    'patch_size': 4,\n",
    "    'in_chans': 3,\n",
    "    'num_classes': 2,\n",
    "    'embed_dim': 96,\n",
    "    'depths': [2, 2, 6, 2],\n",
    "    'num_heads': [3, 6, 12, 24],\n",
    "    'window_size': 7,\n",
    "    'mlp_ratio': 4,\n",
    "    'stochastic_depth_prob': 0.2,\n",
    "}\n",
    "\n",
    "# Instantiate Swin Transformer model. \n",
    "model = SwinTransformer(img_size=swin_config['img_size'],\n",
    "                        patch_size=swin_config['patch_size'],\n",
    "                        in_chans=swin_config['in_chans'],\n",
    "                        num_classes=swin_config['num_classes'],\n",
    "                        embed_dim=swin_config['embed_dim'],\n",
    "                        depths=swin_config['depths'],\n",
    "                        num_heads=swin_config['num_heads'],\n",
    "                        window_size=swin_config['window_size'],\n",
    "                        mlp_ratio=swin_config['mlp_ratio'],\n",
    "                        qkv_bias=True,\n",
    "                        qk_scale=None,\n",
    "                        drop_rate=0.0,\n",
    "                        drop_path_rate=0.1,\n",
    "                        ape=False,\n",
    "                        patch_norm=True,\n",
    "                        use_checkpoint=False,\n",
    "                        fused_window_process=False).to(device)\n",
    "\n",
    "# Generate a summary of the model's architecture\n",
    "#summary(model, (3, 224, 224)) \n",
    "\n",
    "# Set up the Cross Entropy loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the Optimizer as AdamW\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=7.8125e-06,     \n",
    "    betas=(0.9, 0.999), \n",
    "    eps=1.0e-08,      \n",
    "    weight_decay=0.05,   \n",
    ")\n",
    "\n",
    "# Set the Scheduler\n",
    "scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=30,   \n",
    "    eta_min=7.8125e-08  \n",
    ")\n",
    "\n",
    "# Set gradient scaler\n",
    "scaler = amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################################################\n",
      "Epoch 1/100, Train Loss: 0.388358146833782, Time: 11.08 seconds\n",
      "############################################################\n",
      "Epoch 2/100, Train Loss: 0.3869307852769626, Time: 11.14 seconds\n",
      "Val Loss: 0.12823616019026798\n",
      "Current Validation Accuracy: 98.2824427480916%\n",
      "Current Validation Recall: 0.9770992366412213\n",
      "Current Validation F1 Score: 0.982725527831094\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 3/100, Train Loss: 0.3517325643649083, Time: 11.40 seconds\n",
      "############################################################\n",
      "Epoch 4/100, Train Loss: 0.3796776458478838, Time: 11.09 seconds\n",
      "Val Loss: 0.13563043271388972\n",
      "Current Validation Accuracy: 97.70992366412214%\n",
      "Current Validation Recall: 0.9961832061068703\n",
      "Current Validation F1 Score: 0.9775280898876404\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 5/100, Train Loss: 0.382058460947894, Time: 11.12 seconds\n",
      "############################################################\n",
      "Epoch 6/100, Train Loss: 0.3668878317618643, Time: 11.11 seconds\n",
      "Val Loss: 0.13025055714233807\n",
      "Current Validation Accuracy: 96.56488549618321%\n",
      "Current Validation Recall: 0.9770992366412213\n",
      "Current Validation F1 Score: 0.9660377358490566\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 7/100, Train Loss: 0.3796437227998981, Time: 11.11 seconds\n",
      "############################################################\n",
      "Epoch 8/100, Train Loss: 0.3917186727875289, Time: 11.18 seconds\n",
      "Val Loss: 0.188829660528537\n",
      "Current Validation Accuracy: 96.18320610687023%\n",
      "Current Validation Recall: 0.9961832061068703\n",
      "Current Validation F1 Score: 0.9630996309963099\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 9/100, Train Loss: 0.37483930815267197, Time: 11.15 seconds\n",
      "############################################################\n",
      "Epoch 10/100, Train Loss: 0.3868547063747435, Time: 11.14 seconds\n",
      "Val Loss: 0.11957761302421038\n",
      "Current Validation Accuracy: 97.90076335877863%\n",
      "Current Validation Recall: 0.9885496183206107\n",
      "Current Validation F1 Score: 0.9792060491493384\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 11/100, Train Loss: 0.37784182944313716, Time: 11.15 seconds\n",
      "############################################################\n",
      "Epoch 12/100, Train Loss: 0.37071512212962593, Time: 11.18 seconds\n",
      "Val Loss: 0.14533016367843657\n",
      "Current Validation Accuracy: 97.90076335877863%\n",
      "Current Validation Recall: 0.9847328244274809\n",
      "Current Validation F1 Score: 0.9791271347248577\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 13/100, Train Loss: 0.3569400428815652, Time: 11.19 seconds\n",
      "############################################################\n",
      "Epoch 14/100, Train Loss: 0.3833645776426064, Time: 11.15 seconds\n",
      "Val Loss: 0.14319751795494196\n",
      "Current Validation Accuracy: 98.47328244274809%\n",
      "Current Validation Recall: 0.9885496183206107\n",
      "Current Validation F1 Score: 0.9847908745247148\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 15/100, Train Loss: 0.38758519840718225, Time: 11.13 seconds\n",
      "############################################################\n",
      "Epoch 16/100, Train Loss: 0.3687592064464138, Time: 11.17 seconds\n",
      "Val Loss: 0.11393569045784799\n",
      "Current Validation Accuracy: 97.51908396946565%\n",
      "Current Validation Recall: 0.9656488549618321\n",
      "Current Validation F1 Score: 0.9749518304431599\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 17/100, Train Loss: 0.38222535401013974, Time: 11.18 seconds\n",
      "############################################################\n",
      "Epoch 18/100, Train Loss: 0.374780920284395, Time: 11.13 seconds\n",
      "Val Loss: 0.13092778055843982\n",
      "Current Validation Accuracy: 97.13740458015268%\n",
      "Current Validation Recall: 0.9618320610687023\n",
      "Current Validation F1 Score: 0.9710982658959537\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 19/100, Train Loss: 0.37706334985622014, Time: 11.15 seconds\n",
      "############################################################\n",
      "Epoch 20/100, Train Loss: 0.34466465852642786, Time: 11.13 seconds\n",
      "Val Loss: 0.1101256249698274\n",
      "Current Validation Accuracy: 98.2824427480916%\n",
      "Current Validation Recall: 0.9847328244274809\n",
      "Current Validation F1 Score: 0.9828571428571429\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 21/100, Train Loss: 0.3683706014808125, Time: 11.16 seconds\n",
      "############################################################\n",
      "Epoch 22/100, Train Loss: 0.3800689233964636, Time: 11.17 seconds\n",
      "Val Loss: 0.09775067397365064\n",
      "Current Validation Accuracy: 98.2824427480916%\n",
      "Current Validation Recall: 0.9809160305343512\n",
      "Current Validation F1 Score: 0.982791586998088\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 23/100, Train Loss: 0.3629439108585583, Time: 11.21 seconds\n",
      "############################################################\n",
      "Epoch 24/100, Train Loss: 0.3744694462387275, Time: 11.15 seconds\n",
      "Val Loss: 0.1738658994436264\n",
      "Current Validation Accuracy: 96.37404580152672%\n",
      "Current Validation Recall: 1.0\n",
      "Current Validation F1 Score: 0.9650092081031307\n",
      "Model Saved!\n",
      "############################################################\n",
      "Epoch 25/100, Train Loss: 0.3664766461481802, Time: 11.14 seconds\n",
      "############################################################\n",
      "Epoch 26/100, Train Loss: 0.35598466562405795, Time: 11.16 seconds\n",
      "Val Loss: 0.09677413248485237\n",
      "Current Validation Accuracy: 97.90076335877863%\n",
      "Current Validation Recall: 0.9961832061068703\n",
      "Current Validation F1 Score: 0.9793621013133208\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "# Initialize training parameters and lists to track metrics.\n",
    "num_epochs = 100\n",
    "best_accuracy = 0.0\n",
    "best_recall = 0.0\n",
    "best_f1_score = 0.0\n",
    "best_epoch_accuracy = 0\n",
    "best_model_path = '/home/ee22s501/cvip/code/save'\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "precision,recall_anil,specificity=[],[],[]\n",
    "\n",
    "# Main training loop over epochs.\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training loop over batches.\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Apply MixUp augmentation.\n",
    "        if np.random.rand() < 0.5:\n",
    "            images, targets_a, targets_b, lam = mixup(images, labels, alpha=1.0)\n",
    "        else:\n",
    "            images, targets_a, targets_b, lam = mixup(images, labels, alpha=1.0)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with amp.autocast():\n",
    "            outputs = model(images)\n",
    "            #loss = criterion(outputs, labels)\n",
    "            loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        #scheduler.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(running_loss/len(train_loader))\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(\"############################################################\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {running_loss/len(train_loader)}, Time: {epoch_time:.2f} seconds\")\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        TP=0\n",
    "        FN=0\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        # Validation loop to evaluate model performance.\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                TP += sum(1 for x, y in zip(predicted, labels) if x == y == 1)\n",
    "                FN += sum(1 for x, y in zip(predicted, labels) if x != y and  y==1)\n",
    "\n",
    "                val_predictions.extend(predicted.cpu().numpy())\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "                val_loss = criterion(outputs, labels)   \n",
    "                running_val_loss += val_loss.item()\n",
    "\n",
    "        TN=correct - TP\n",
    "        FP=(total-correct) - FN\n",
    "\n",
    "        val_precision= TP/(TP+FP)\n",
    "        precision.append(val_precision)\n",
    "        val_recall=TP/(TP+FN)\n",
    "        recall_anil.append(val_recall)\n",
    "        val_specificity=TN/(TN+FP)\n",
    "        specificity.append(val_specificity)\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        val_losses.append(running_val_loss/len(val_loader))\n",
    "\n",
    "        # Print and save model performance metrics.\n",
    "        print(f\"Val Loss: {running_val_loss/len(val_loader)}\")\n",
    "        val_accuracies.append(accuracy)\n",
    "        recall = recall_score(val_labels, val_predictions)\n",
    "        f1 = f1_score(val_labels, val_predictions)\n",
    "\n",
    "        print(f\"Current Validation Accuracy: {accuracy}%\")\n",
    "        print(f\"Current Validation Recall: {recall}\")\n",
    "        print(f\"Current Validation F1 Score: {f1}\")\n",
    "\n",
    "        # Save the model.\n",
    "        model_path = os.path.join(best_model_path, f\"model_classify_{epoch + 1}.pth\")\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Model Saved!\")\n",
    "\n",
    "# Plot training and validation metrics.\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, num_epochs + 1, 1), train_losses, label='Train Loss', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(2, num_epochs + 1, 2), val_losses, label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(2, num_epochs + 1, 2), val_accuracies, label='Validation Accuracy', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing & Dataloader for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining data preprocessing for test data.\n",
    "test_transform = transforms.Compose([\n",
    "    #lambda x: rgb_to_lab_and_clahe(x, clip_limit=5.0, tile_grid_size=(8, 8), blur_sigma=1.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "#Defining path for saving test prediction, model checkpoint, CAMs, and Excel file\n",
    "test_data_path = '/home/ee22s501/cvip/code/dummy'\n",
    "model_path = '/home/ee22s501/c2/code/save/model_classify_72.pth'\n",
    "cams_path = '/home/ee22s501/c2/code/save/cams/'\n",
    "excel_file_path = '/home/ee22s501/c2/code/save/predictions_classify.xlsx'\n",
    "batch_size = 1\n",
    "\n",
    "# Create a test dataset and data loader for inference.\n",
    "test_dataset = ImageFolder(test_data_path, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and CAM plot generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([1], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n",
      "Predictions saved to /home/ee22s501/c2/code/save/predictions_classify.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Define a function to reshape a tensor for Ablation-CAM function \n",
    "def reshape_transform(tensor, height=7, width=7):\n",
    "    \"\"\"\n",
    "    Reshape a tensor to the specified height and width dimensions.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor.\n",
    "        height (int): Target height dimension.\n",
    "        width (int): Target width dimension.\n",
    "\n",
    "    Returns:\n",
    "        result (torch.Tensor): Reshaped tensor.\n",
    "    \"\"\"\n",
    "    result = tensor.reshape(tensor.size(0), height, width, tensor.size(2))\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result \n",
    "\n",
    "\n",
    "# Load a pre-trained model and set it to evaluation mode.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Define class names, fonts, and variables for predictions and image file names.\n",
    "class_names = ['bleeding', 'non_bleeding']\n",
    "i = 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "font_color = (255, 255, 255)\n",
    "font_thickness = 1\n",
    "predicted_labels = []\n",
    "image_file_names = []\n",
    "\n",
    "# Loop through test data and generate predictions.\n",
    "for images, _ in test_loader:\n",
    "    images = images.to(device)\n",
    "    outputs = model(images)\n",
    "    #print(outputs)\n",
    "    _, predicted = torch.min(outputs.data, 1)\n",
    "    print(predicted)\n",
    "    predicted_label = class_names[predicted.item()-1]\n",
    "\n",
    "# Uncomment this code for generating Ablation-CAM plots. \n",
    "    # target_layers = [model.layers[-1].blocks[-1].norm2]\n",
    "    # cam = AblationCAM(model=model, target_layers=target_layers, reshape_transform=reshape_transform, ablation_layer=AblationLayerVit())\n",
    "    # grayscale_cam = cam(input_tensor=images, aug_smooth=True, eigen_smooth=True, targets=None)\n",
    "    # rgb_img = cv2.imread(test_loader.dataset.samples[i][0], 1)[:, :, ::-1]\n",
    "    # rgb_img_n = np.float32(rgb_img) / 255\n",
    "    # cam_image = show_cam_on_image(rgb_img_n, grayscale_cam[0, :])\n",
    "\n",
    "    # predicted_labels.append(predicted_label)\n",
    "    # image_file_names.append(os.path.basename(test_loader.dataset.samples[i][0]))\n",
    "\n",
    "    # combined_image = np.copy(cam_image)\n",
    "    # text = f'Predicted: {predicted_label}'\n",
    "    # cv2.putText(combined_image, text, (15, 15), font, font_scale, font_color, font_thickness)\n",
    "    # cv2.imwrite(os.path.join(cams_path, os.path.basename(test_loader.dataset.samples[i][0])), combined_image)\n",
    "\n",
    "    ## Append predicted labels and image file names.\n",
    "    file_name = os.path.splitext(os.path.basename(test_loader.dataset.samples[i][0]))[0]\n",
    "    image_file_names.append(file_name)\n",
    "    predicted_labels.append(predicted.item())\n",
    "    i += 1\n",
    "\n",
    "# Create a DataFrame and save predictions to an Excel file.\n",
    "data = {\n",
    "    'Image name': image_file_names,\n",
    "    'Predicted Class label': predicted_labels,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['Predicted Class label'] = df['Predicted Class label'].map({0: 'Bleeding', 1: 'Non-Bleeding'})\n",
    "\n",
    "df.to_excel(excel_file_path, index=False)\n",
    "print(f\"Predictions saved to {excel_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
